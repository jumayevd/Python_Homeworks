{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merging and Joining**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from the Chinook database\n",
    "with sqlite3.connect('data/chinook.db') as con:\n",
    "    df_customers = pd.read_sql_query('SELECT CustomerId, FirstName, LastName FROM customers', con)\n",
    "    df_invoices = pd.read_sql_query('SELECT InvoiceId, CustomerId FROM invoices', con)\n",
    "\n",
    "# Perform an inner join on the CustomerId column\n",
    "merged_df = pd.merge(df_customers, df_invoices, on='CustomerId', how='inner')\n",
    "\n",
    "# Count the number of invoices for each customer\n",
    "customer_invoice_counts = (\n",
    "    merged_df.groupby(['CustomerId', 'FirstName', 'LastName'])\n",
    "    .size()\n",
    "    .reset_index(name='TotalInvoices')\n",
    "    .sort_values(by='TotalInvoices', ascending=False)\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "print(customer_invoice_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the movie.csv file\n",
    "file_path = 'data/movie.csv' \n",
    "movies = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Create two smaller DataFrames\n",
    "df_director_color = movies[['director_name', 'color']]\n",
    "df_director_reviews = movies[['director_name', 'num_critic_for_reviews']]\n",
    "\n",
    "# Step 3: Perform a left join\n",
    "left_join = pd.merge(df_director_color, df_director_reviews, on='director_name', how='left')\n",
    "\n",
    "# Step 4: Perform a full outer join\n",
    "outer_join = pd.merge(df_director_color, df_director_reviews, on='director_name', how='outer')\n",
    "\n",
    "# Step 5: Count the number of rows in each resulting DataFrame\n",
    "print(f\"Rows in left join DataFrame: {len(left_join)}\")\n",
    "print(f\"Rows in outer join DataFrame: {len(outer_join)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grouping and Aggregating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the Titanic dataset\n",
    "# Replace 'data/titanic.csv' with the correct path to your Titanic dataset file\n",
    "titanic = pd.read_excel('data/titanic.xlsx')\n",
    "\n",
    "# Perform grouped aggregation by Pclass\n",
    "grouped_results = titanic.groupby('Pclass').agg(\n",
    "    Average_Age=('Age', 'mean'),      # Calculate average age\n",
    "    Total_Fare=('Fare', 'sum'),       # Calculate total fare\n",
    "    Passenger_Count=('PassengerId', 'count')  # Count passengers\n",
    ").reset_index()\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(grouped_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the movie data\n",
    "movies = pd.read_csv('data/movie.csv')\n",
    "\n",
    "# Perform multi-level grouping by 'color' and 'director_name'\n",
    "grouped_results = movies.groupby(['color', 'director_name']).agg(\n",
    "    Total_Num_Critic_Reviews=('num_critic_for_reviews', 'sum'),  # Total critic reviews\n",
    "    Average_Duration=('duration', 'mean')  # Average duration\n",
    ").reset_index()\n",
    "\n",
    "# Display the results\n",
    "print(grouped_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the flight data\n",
    "flights = pd.read_parquet('data/flights', columns=['Year', 'Month', 'ArrDelay', 'DepDelay', 'Flights'])\n",
    "\n",
    "# Drop rows with missing values in relevant columns\n",
    "flights['ArrDelay'] = pd.to_numeric(flights['ArrDelay'], errors='coerce')\n",
    "flights = flights[pd.to_numeric(flights['ArrDelay'], errors='coerce').notna()]\n",
    "cleaned_flights = flights.dropna(subset=['ArrDelay', 'DepDelay', 'Flights'])\n",
    "\n",
    "# Step 2: Perform nested grouping by 'Year' and 'Month'\n",
    "grouped_results = cleaned_flights.groupby(['Year', 'Month']).agg(\n",
    "    Total_Flights=('Flights', 'count'),        # Total number of flights\n",
    "    Average_Arrival_Delay=('ArrDelay', 'mean'),  # Average arrival delay\n",
    "    Max_Departure_Delay=('DepDelay', 'max')      # Maximum departure delay\n",
    ").reset_index()\n",
    "\n",
    "# Step 3: Display the results\n",
    "grouped_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying Functions**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Titanic dataset\n",
    "titanic_df = pd.read_excel('data/titanic.xlsx')\n",
    "\n",
    "# Define the custom function to classify passengers\n",
    "def classify_age(age):\n",
    "    if pd.isna(age):  # Handle missing values\n",
    "        return \"Unknown\"\n",
    "    elif age < 18:\n",
    "        return \"Child\"\n",
    "    else:\n",
    "        return \"Adult\"\n",
    "\n",
    "# Apply the function to the 'Age' column and create a new column 'Age_Group'\n",
    "titanic_df['Age_Group'] = titanic_df['Age'].apply(classify_age)\n",
    "\n",
    "# Display the first few rows to verify the new column\n",
    "print(titanic_df[['Age', 'Age_Group']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('data/employee.csv')\n",
    "\n",
    "# Ensure the relevant columns are present\n",
    "if 'DEPARTMENT' in df.columns and 'BASE_SALARY' in df.columns:\n",
    "    employees = df[['DEPARTMENT', 'BASE_SALARY']]\n",
    "else:\n",
    "    raise ValueError(\"The required columns 'DEPARTMENT' and 'BASE_SALARY' are not present in the CSV file.\")\n",
    "\n",
    "# Step 3: Normalize the salaries within each department\n",
    "def normalize_salaries(group):\n",
    "    # Min-Max Normalization\n",
    "    group['NORMALIZED_SALARY'] = (group['BASE_SALARY'] - group['BASE_SALARY'].min()) / (group['BASE_SALARY'].max() - group['BASE_SALARY'].min())\n",
    "    return group\n",
    "\n",
    "# Apply the normalization within each department\n",
    "normalized_employees = employees.groupby('DEPARTMENT', group_keys=False).apply(normalize_salaries).reset_index(drop=True)\n",
    "\n",
    "# Display the normalized data\n",
    "normalized_employees.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the employee data\n",
    "emp_df = pd.read_csv('data/employee.csv')\n",
    "\n",
    "# Define a function to normalize salaries within a group\n",
    "def normalize_salaries(group):\n",
    "    mean_salary = group.mean()\n",
    "    std_salary = group.std()\n",
    "    # Avoid division by zero if all salaries are the same (std = 0)\n",
    "    if std_salary == 0:\n",
    "        return 0\n",
    "    return (group - mean_salary) / std_salary\n",
    "\n",
    "# Apply the normalization within each department (grouped by DEPARTMENT)\n",
    "emp_df['Normalized_Salary'] = emp_df.groupby('DEPARTMENT')['BASE_SALARY'].transform(normalize_salaries)\n",
    "\n",
    "# Display the result\n",
    "print(emp_df[['BASE_SALARY', 'Normalized_Salary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "movie_df = pd.read_csv('data/movie.csv')\n",
    "\n",
    "\n",
    "# Defining the function\n",
    "def classify_movie_duration(duration):\n",
    "    if duration < 60:\n",
    "        return \"Short\"\n",
    "    elif 60 <= duration <= 120:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Long\"\n",
    "    \n",
    "# Apply the function to the 'duration' column\n",
    "movie_df['duration_category'] = movie_df['duration'].apply(classify_movie_duration)\n",
    "\n",
    "# View the result\n",
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using pipe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Titanic dataset\n",
    "titanic_df = pd.read_excel('data/titanic.xlsx')\n",
    "\n",
    "# Define the pipeline functions\n",
    "def filter_survivors(df):\n",
    "    return df[df['Survived'] == 1]\n",
    "\n",
    "def fill_missing_age(df):\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "    return df\n",
    "\n",
    "def add_fare_per_age(df):\n",
    "    df['Fare_Per_Age'] = df['Fare'] / df['Age']\n",
    "    return df\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = (titanic_df.pipe(filter_survivors)\n",
    "              .pipe(fill_missing_age)\n",
    "              .pipe(add_fare_per_age))\n",
    "\n",
    "# Display the result\n",
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the flight data\n",
    "df_flights = pd.read_parquet('data/flights', columns=['DepDelay', 'Scheduled_Duration'])\n",
    "\n",
    "\n",
    "# Define the pipeline functions\n",
    "def filter_delays(df):\n",
    "    return df[df['DepDelay'] > 30]\n",
    "\n",
    "def add_delay_per_hour(df):\n",
    "    df['Delay_Per_Hour'] = df['DepDelay'] / df['Scheduled_Duration']\n",
    "    return df\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = (df.pipe(filter_delays)\n",
    "                  .pipe(add_delay_per_hour))\n",
    "\n",
    "# Display the result\n",
    "print(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
