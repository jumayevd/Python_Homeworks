{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db():\n",
    "    with sqlite3.connect('jobs.db') as con:\n",
    "        cursor = con.cursor()\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS jobs (\n",
    "                job_title TEXT,\n",
    "                company_name TEXT,\n",
    "                location TEXT,\n",
    "                job_description TEXT,\n",
    "                application_link TEXT,\n",
    "                UNIQUE(job_title, company_name, location)\n",
    "            )\n",
    "        ''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_description(application_link):\n",
    "    try:\n",
    "        res = requests.get(application_link)\n",
    "        soup = BeautifulSoup(res.content, 'html.parser')\n",
    "        description = soup.find('div', class_ = 'content')\n",
    "        if description:\n",
    "                return description.text.strip()\n",
    "        else:\n",
    "                return \"No description found.\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "                return f\"Error fetching description: {e}\"\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_jobs():\n",
    "    response = requests.get('https://realpython.github.io/fake-jobs')\n",
    "    soup = BeautifulSoup(response.content)\n",
    "    jobs = []\n",
    "    job_cards = soup.find_all('div', class_ = 'card-content')\n",
    "    for card in job_cards:\n",
    "        job_title = card.find('h2', class_='title').text.strip()\n",
    "        company_name = card.find('h3', class_ = 'subtitle').text.strip()\n",
    "        location = card.find('p', class_= 'location').text.strip()\n",
    "        application_link = None\n",
    "        links = card.find_all('a', class_='card-footer-item')\n",
    "        for link in links:\n",
    "            if \"Apply\" in link.text:  # Ensure we get the Apply Now link\n",
    "                application_link = link['href']\n",
    "                break\n",
    "\n",
    "        # Fetch the job description by visiting the application link\n",
    "        job_description = \"No description available\"  # Default in case there's no application link\n",
    "        if application_link:\n",
    "            job_description = get_job_description(application_link)  # Fetch description from the application page\n",
    "\n",
    "        # Append extracted data to the jobs list\n",
    "        jobs.append({\n",
    "            'Job Title': job_title,\n",
    "            'Company Name': company_name,\n",
    "            'Location': location,\n",
    "            'Job Description': job_description,\n",
    "            'Application Link': application_link\n",
    "        })\n",
    "    return jobs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_to_db(jobs):\n",
    "    with sqlite3.connect('jobs.db') as con:\n",
    "        cursor = con.cursor()\n",
    "        for job in jobs:\n",
    "            cursor.execute('''\n",
    "                INSERT INTO jobs (job_title, company_name, location, job_description, application_link)\n",
    "                VALUES (?, ?, ?, ?, ?) \n",
    "                ON CONFLICT(job_title, company_name, location) \n",
    "                DO UPDATE SET\n",
    "                    job_description = excluded.job_description,\n",
    "                    application_link = excluded.application_link\n",
    "            ''', (\n",
    "                job['Job Title'],\n",
    "                job['Company Name'],\n",
    "                job['Location'],\n",
    "                job['Job Description'],\n",
    "                job['Application Link']\n",
    "            ))\n",
    "        con.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_jobs(filter_by, value):\n",
    "    \"\"\"Filters jobs by a specific column (location or company_name).\"\"\"\n",
    "    with sqlite3.connect('jobs.db') as con:\n",
    "        cursor = con.cursor()\n",
    "        cursor.execute(f'''\n",
    "            SELECT job_title, company_name, location, job_description, application_link \n",
    "            FROM jobs\n",
    "            WHERE {filter_by} LIKE ?\n",
    "        ''', (f'%{value}%',))\n",
    "        return cursor.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_csv(data, filename):\n",
    "    \"\"\"Exports filtered job data to a CSV file.\"\"\"\n",
    "    with open(filename, 'w') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Job Title', 'Company Name', 'Location', 'Job Description', 'Application Link'])\n",
    "        writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered jobs for location 'Remote' have been exported to CSV.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to orchestrate the scraping and storing process.\"\"\"\n",
    "    create_db()\n",
    "    jobs = scrap_jobs()\n",
    "    store_to_db(jobs)\n",
    "\n",
    "    # Example: Filter and export jobs for a specific location\n",
    "    location_filter = \"Remote\"\n",
    "    filtered_jobs = filter_jobs('location', location_filter)\n",
    "    export_to_csv(filtered_jobs, f'jobs_filtered_by_{location_filter}.csv')\n",
    "\n",
    "    print(f\"Filtered jobs for location '{location_filter}' have been exported to CSV.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
